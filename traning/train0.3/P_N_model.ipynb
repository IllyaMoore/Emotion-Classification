{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efc891b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.1-cp313-cp313-win_amd64.whl.metadata (10 kB)\n",
      "Downloading sentencepiece-0.2.1-cp313-cp313-win_amd64.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 9.2 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "491d8c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:12: SyntaxWarning: invalid escape sequence '\\E'\n",
      "<>:12: SyntaxWarning: invalid escape sequence '\\E'\n",
      "C:\\Users\\illya\\AppData\\Local\\Temp\\ipykernel_26308\\448116470.py:12: SyntaxWarning: invalid escape sequence '\\E'\n",
      "  TOKENIZER = 'C:\\Emotion Classification\\\\traning\\\\vocab\\\\tokenizer.model'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import sentencepiece as spm\n",
    "\n",
    "P_df = pd.read_csv(\"C:\\\\Emotion Classification\\\\treeModelsData\\\\positive_emotions.csv\")\n",
    "N_df = pd.read_csv(\"C:\\\\Emotion Classification\\\\treeModelsData\\\\negative_emotions.csv\")\n",
    "TOKENIZER = 'C:\\Emotion Classification\\\\traning\\\\vocab\\\\tokenizer.model'\n",
    "\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(TOKENIZER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "05ba71ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43332, 26)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_df.shape[0] + N_df.shape[0], P_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a8a73b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text              object\n",
       "admiration         int64\n",
       "amusement          int64\n",
       "anger              int64\n",
       "annoyance          int64\n",
       "approval           int64\n",
       "caring             int64\n",
       "confusion          int64\n",
       "curiosity          int64\n",
       "desire             int64\n",
       "disappointment     int64\n",
       "disapproval        int64\n",
       "disgust            int64\n",
       "embarrassment      int64\n",
       "excitement         int64\n",
       "fear               int64\n",
       "gratitude          int64\n",
       "grief              int64\n",
       "joy                int64\n",
       "love               int64\n",
       "nervousness        int64\n",
       "optimism           int64\n",
       "pride              int64\n",
       "relief             int64\n",
       "remorse            int64\n",
       "sadness            int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6e2ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3633530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21153"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_index = int(P_df.shape[0] * 0.8)\n",
    "split_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4763c1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_text(data):\n",
    "    data = data.copy()\n",
    "    \n",
    "    data[\"text\"] = data[\"text\"].apply(lambda x: sp.encode(x, out_type=int))\n",
    "    y = data.drop(columns=['text'])\n",
    "    \n",
    "    list_of_lists = data['text'].tolist()\n",
    "    tensor_list = [torch.tensor(seq, dtype=torch.long) for seq in list_of_lists]\n",
    "    X = pad_sequence(tensor_list, batch_first=True, padding_value=0)\n",
    "    y = torch.tensor(y.values, dtype=torch.long)\n",
    "    \n",
    "    X_train = X[:split_index]\n",
    "    X_test = X[split_index:]\n",
    "    \n",
    "    y_train = y[:split_index]\n",
    "    y_test = y[split_index:]\n",
    "    \n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "    \n",
    "X_train, y_train, X_test, y_test = pipeline_text(P_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d45b67ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_ds = TensorDataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
