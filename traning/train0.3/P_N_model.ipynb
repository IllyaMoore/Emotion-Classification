{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "efc891b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentencepiece\n",
      "  Downloading sentencepiece-0.2.1-cp313-cp313-win_amd64.whl.metadata (10 kB)\n",
      "Downloading sentencepiece-0.2.1-cp313-cp313-win_amd64.whl (1.1 MB)\n",
      "   ---------------------------------------- 0.0/1.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.1/1.1 MB 9.2 MB/s eta 0:00:00\n",
      "Installing collected packages: sentencepiece\n",
      "Successfully installed sentencepiece-0.2.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "491d8c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:16: SyntaxWarning: invalid escape sequence '\\E'\n",
      "<>:16: SyntaxWarning: invalid escape sequence '\\E'\n",
      "C:\\Users\\illya\\AppData\\Local\\Temp\\ipykernel_21808\\684743216.py:16: SyntaxWarning: invalid escape sequence '\\E'\n",
      "  TOKENIZER = \"C:\\Emotion Classification\\\\traning\\\\vocab\\\\tokenizer0.2.json\"\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "from transformers import pipeline\n",
    "import pandas as pd\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import sentencepiece as spm\n",
    "from tokenizers import Tokenizer\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch.nn.functional as F\n",
    "\n",
    "P_df = pd.read_csv(\"C:\\\\Emotion Classification\\\\treeModelsData\\\\positive_emotions.csv\")\n",
    "N_df = pd.read_csv(\"C:\\\\Emotion Classification\\\\treeModelsData\\\\negative_emotions.csv\")\n",
    "\n",
    "TOKENIZER = \"C:\\Emotion Classification\\\\traning\\\\vocab\\\\tokenizer0.2.json\"\n",
    "\n",
    "tokenizer = Tokenizer.from_file(TOKENIZER)\n",
    "\n",
    "batchsize = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "05ba71ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43332, 14)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_df.shape[0] + N_df.shape[0], P_df.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a8a73b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "text          object\n",
       "admiration     int64\n",
       "amusement      int64\n",
       "approval       int64\n",
       "caring         int64\n",
       "curiosity      int64\n",
       "desire         int64\n",
       "excitement     int64\n",
       "gratitude      int64\n",
       "joy            int64\n",
       "love           int64\n",
       "optimism       int64\n",
       "pride          int64\n",
       "relief         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "6fa9d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "P_df['text'] = P_df['text'].str.lower()\n",
    "N_df['text'] = N_df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "9682cd93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>admiration</th>\n",
       "      <th>amusement</th>\n",
       "      <th>approval</th>\n",
       "      <th>caring</th>\n",
       "      <th>curiosity</th>\n",
       "      <th>desire</th>\n",
       "      <th>excitement</th>\n",
       "      <th>gratitude</th>\n",
       "      <th>joy</th>\n",
       "      <th>love</th>\n",
       "      <th>optimism</th>\n",
       "      <th>pride</th>\n",
       "      <th>relief</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16608</th>\n",
       "      <td>ughh same. love the finish of it just wish it ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  admiration  \\\n",
       "16608  ughh same. love the finish of it just wish it ...           0   \n",
       "\n",
       "       amusement  approval  caring  curiosity  desire  excitement  gratitude  \\\n",
       "16608          0         0       0          0       0           0          0   \n",
       "\n",
       "       joy  love  optimism  pride  relief  \n",
       "16608    0     1         0      0       0  "
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "P_df.sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "f3633530",
   "metadata": {},
   "outputs": [],
   "source": [
    "split_index = int(P_df.shape[0] * 0.8)\n",
    "split_index\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "cbd615da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 128)"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = tokenizer.get_vocab_size()\n",
    "embedding_dim = 128\n",
    "vocab_size, embedding_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "4763c1d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 720,   51,  681, 1141,   18])\n",
      "tensor([ 720,   51,  681, 1141,   18,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
      "           0,    0])\n"
     ]
    }
   ],
   "source": [
    "def pipeline_text(data):\n",
    "    data = data.copy()\n",
    "    \n",
    "    data[\"text\"] = data[\"text\"].apply(lambda x: (tokenizer.encode(x)).ids)\n",
    "    y = data.drop(columns=['text'])\n",
    "    \n",
    "    list_of_lists = data['text'].tolist()\n",
    "    tensor_list = [torch.tensor(seq, dtype=torch.long) for seq in list_of_lists]\n",
    "    print(tensor_list[0])\n",
    "    X = pad_sequence(tensor_list, batch_first=True, padding_value=0)\n",
    "    print(X[0])\n",
    "    y = torch.tensor(y.values, dtype=torch.float32)\n",
    "    \n",
    "    X_train = X[:split_index]\n",
    "    X_test = X[split_index:]\n",
    "    \n",
    "    y_train = y[:split_index]\n",
    "    y_test = y[split_index:]\n",
    "    \n",
    "    \n",
    "    return X_train, y_train, X_test, y_test\n",
    "    \n",
    "X_train, y_train, X_test, y_test = pipeline_text(P_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "a1705aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([21153, 62]),\n",
       " torch.Size([21153, 13]),\n",
       " torch.Size([5289, 62]),\n",
       " torch.Size([5289, 13]),\n",
       " torch.Tensor,\n",
       " torch.Tensor,\n",
       " torch.Tensor,\n",
       " torch.Tensor)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape, type(X_train), type(y_train), type(X_test), type(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "d45b67ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batchsize, shuffle=True, num_workers=2)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batchsize, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "003ba6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_len = X_train.shape[1]\n",
    "input_len = X_train.shape[1]\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "num_classes = y_train.shape[1]\n",
    "num_epochs = 5\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "0183a602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class LSTM(nn.Module):\n",
    "#     def __init__(self, input_len, hidden_size, num_layers, num_classes):\n",
    "#         super(LSTM, self).__init__()\n",
    "#         self.hidden_size = hidden_size\n",
    "#         self.num_layers = num_layers\n",
    "#         self.lstm = nn.LSTM(input_len, hidden_size, num_layers, batch_first=True)\n",
    "#         self.output_layer = nn.Linear(hidden_size, num_classes) \n",
    "    \n",
    "#     def forward(self, X):\n",
    "#         hidden_size = torch.zeros(self.num_layers, X.size(0), self.hidden_size)\n",
    "#         cell_state = torch.zeros(self.num_layers, X.size(0), self.hidden_size)\n",
    "#         out, _ = self.lstm(X, (hidden_size, cell_state))\n",
    "#         out = self.output_layer(out[:, -1, :])\n",
    "#         return out\n",
    "    \n",
    "    \n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_size, num_layers, num_classesб, dropout=0.3):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        \n",
    "        self.lstm = nn.LSTM(\n",
    "            embedding_dim, \n",
    "            hidden_size, \n",
    "            num_layers=num_layers,  # Збільшуємо кількість LSTM шарів\n",
    "            batch_first=True, \n",
    "            dropout=dropout if num_layers > 1 else 0,  # Dropout між LSTM шарами\n",
    "            bidirectional=False  # Можна змінити на True при потребі\n",
    "        )\n",
    "        self.dropout1 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_size, hidden_size // 2)\n",
    "        self.bn1 = nn.BatchNorm1d(hidden_size // 2)  # Batch normalization\n",
    "        self.dropout2 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.fc2 = nn.Linear(hidden_size // 2, hidden_size // 4)\n",
    "        self.bn2 = nn.BatchNorm1d(hidden_size // 4)\n",
    "        self.dropout3 = nn.Dropout(dropout * 0.5)  # Менший dropout в кінці\n",
    "        \n",
    "        # Вихідний шар\n",
    "        self.output_layer = nn.Linear(hidden_size // 4, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # Embedding\n",
    "        embedded = self.embedding(x)\n",
    "        \n",
    "        # LSTM\n",
    "        lstm_out, (hidden, cell) = self.lstm(embedded)\n",
    "        \n",
    "        # Використовуємо останній hidden state\n",
    "        out = lstm_out[:, -1, :]  # Беремо останню позицію\n",
    "        \n",
    "        # Dropout після LSTM\n",
    "        out = self.dropout1(out)\n",
    "        \n",
    "        # Перший FC шар + BatchNorm + ReLU + Dropout\n",
    "        out = self.fc1(out)\n",
    "        out = self.bn1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.dropout2(out)\n",
    "        \n",
    "        # Другий FC шар + BatchNorm + ReLU + Dropout\n",
    "        out = self.fc2(out)\n",
    "        out = self.bn2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.dropout3(out)\n",
    "        \n",
    "        # Вихідний шар\n",
    "        out = self.output_layer(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "id": "12e77b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = LSTMModel(input_len, hidden_size, num_layers, num_classes)\n",
    "model = LSTMModel(vocab_size, hidden_size, hidden_size, num_layers, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "c8b5bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# loss_func = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "id": "90a3faf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(num_epochs, model, train_dataloader, loss_func):\n",
    "    total_step = len(train_dataloader)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for batch, (text_r, lables) in enumerate(train_dataloader):\n",
    "\n",
    "            outputs = model(text_r)\n",
    "            loss = loss_func(outputs, lables)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            if (batch + 1) % 100 == 0:\n",
    "                print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{batch + 1}/{total_step}], Loss: {loss.item():.4f}, Accuracy: {torch.sum(torch.argmax(outputs, dim=1) == torch.argmax(lables, dim=1)).item() / len(lables):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "id": "91e612a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'F' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[329]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloss_func\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[328]\u001b[39m\u001b[32m, line 7\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(num_epochs, model, train_dataloader, loss_func)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_epochs):\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m batch, (text_r, lables) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(train_dataloader):\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m         outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext_r\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m         loss = loss_func(outputs, lables)\n\u001b[32m     10\u001b[39m         optimizer.zero_grad()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Emotion Classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1773\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1771\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1772\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Emotion Classification\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1784\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1779\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1780\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1781\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1782\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1783\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1784\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1786\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1787\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[325]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mLSTMModel.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     57\u001b[39m out = \u001b[38;5;28mself\u001b[39m.fc1(out)\n\u001b[32m     58\u001b[39m out = \u001b[38;5;28mself\u001b[39m.bn1(out)\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m out = \u001b[43mF\u001b[49m.relu(out)\n\u001b[32m     60\u001b[39m out = \u001b[38;5;28mself\u001b[39m.dropout2(out)\n\u001b[32m     62\u001b[39m \u001b[38;5;66;03m# Другий FC шар + BatchNorm + ReLU + Dropout\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'F' is not defined"
     ]
    }
   ],
   "source": [
    "train(num_epochs=num_epochs, model=model, train_dataloader=train_dataloader, loss_func=loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d6de9d",
   "metadata": {},
   "source": [
    "Epoch [1/5], Step [100/212], Loss: 3.0014, Accuracy: 0.1600\n",
    "Epoch [1/5], Step [200/212], Loss: 3.0891, Accuracy: 0.1600\n",
    "Epoch [2/5], Step [100/212], Loss: 3.0311, Accuracy: 0.1800\n",
    "Epoch [2/5], Step [200/212], Loss: 3.1607, Accuracy: 0.2200\n",
    "Epoch [3/5], Step [100/212], Loss: 2.8715, Accuracy: 0.2000\n",
    "Epoch [3/5], Step [200/212], Loss: 2.9521, Accuracy: 0.1900\n",
    "Epoch [4/5], Step [100/212], Loss: 3.0117, Accuracy: 0.1900\n",
    "Epoch [4/5], Step [200/212], Loss: 2.7980, Accuracy: 0.2200\n",
    "Epoch [5/5], Step [100/212], Loss: 2.7254, Accuracy: 0.2200\n",
    "Epoch [5/5], Step [200/212], Loss: 2.8732, Accuracy: 0.1900"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
